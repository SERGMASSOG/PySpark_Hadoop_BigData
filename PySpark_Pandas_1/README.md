# PySpark y Pandas laboratorio Data Engineering / Data Science

## 游닂 Introducci칩n

Este proyecto combina el poder de **PySpark** y **Pandas** para abordar tareas de an치lisis de datos desde dos enfoques complementarios: el procesamiento distribuido a gran escala y la manipulaci칩n eficiente en memoria. A trav칠s de esta integraci칩n, se busca aprovechar lo mejor de ambos mundos para construir flujos de trabajo robustos, escalables y 치giles.

- **PySpark** es la interfaz de Python para Apache Spark, dise침ada para ejecutar operaciones sobre grandes vol칰menes de datos distribuidos en m칰ltiples nodos. Es ideal para entornos donde los datos superan la capacidad de una sola m치quina, como en escenarios de Big Data.
- **Pandas**, por su parte, es una biblioteca especializada en el manejo de datos estructurados en memoria. Ofrece herramientas vers치tiles para la limpieza, transformaci칩n y an치lisis exploratorio, siendo especialmente 칰til en etapas de prototipado y validaci칩n r치pida.

## 游꿢 Objetivos

- **Comprender PySpark y Pandas**  
  Aplicar sus funcionalidades en procesamiento distribuido y manipulaci칩n de datos estructurados.

- **Configurar el entorno**  
  Instalar y preparar PySpark y Pandas para trabajar de forma conjunta en un entorno Python.

- **Cargar y explorar datos**  
  Importar conjuntos de datos en DataFrames de Pandas y PySpark, y realizar exploraciones b치sicas para entender su estructura.

- **Convertir entre DataFrames**  
  Transformar un DataFrame de Pandas en uno de PySpark para aprovechar el procesamiento distribuido.

- **Manipular datos con PySpark**  
  Crear columnas nuevas, aplicar filtros y realizar agregaciones utilizando las funciones propias de PySpark.

- **Ejecutar consultas SQL**  
  Utilizar Spark SQL para realizar consultas sobre los datos y aplicar funciones definidas por el usuario (UDFs) para extender la l칩gica de an치lisis.

- **Visualizaci칩n y miner칤a de datos**  
  Realizar procesamiento avanzado y toma de decisiones basada en t칠cnicas de miner칤a de datos.

